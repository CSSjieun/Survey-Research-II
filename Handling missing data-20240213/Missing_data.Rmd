---
title: "How to handle missing data?"
author: "Marga Torre"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: yes
    df_print: paged
---

```{=html}
<style>
body {
text-align: justify}
</style>
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=T, message=FALSE, warning=FALSE, knitr.purl.inline = TRUE )
```

## Intro

When dealing with missing data, data scientists use two primary methods to address the issue:

#When there is many NAs in the data
-   __Listwise-deletion__ (also called Complete Case Analysis): This method involves deleting rows in your dataset that contain missing data (such as NAs, NaN, etc.). If the amount of missing data is very small, this might be the most straightforward approach to ensure your analysis is not biased. However, there are drawbacks:

-   Deleting data points can lead to the loss of valuable information, especially if the dataset is small.
-   It reduces the degrees of freedom in statistical analysis.
-   It may result in discarding valid data points simply because one column value is missing
    
#If the data is homogeneous then it would not be a problem, but if the dataset are heterogeneous then it can be a problem. 
-   __Mean/median substitution__: another quick fix is to take the mean/median of the existing data points and substitute missing data points with the mean/median. While it doesn’t change the mean of the dataset, it could cause bias in the analysis since it decreases variance (if you have a lot of missing data and you are replacing them with a fixed number). 

Despite their evident shortcomings, these methods represent the most frequently utilized strategies for addressing missing data in quantitative research.

## Multiple imputation

Multiple imputation requires more work than the previous two options. With this approach, rather than replacing missing values with a single value, we use the distribution of the observed data/variables to estimate multiple possible values for the data points. This allows us to account for the uncertainty around the true value, and obtain approximately unbiased estimates (under certain conditions). 

Rubin (1976) proposed a __five-step procedure to impute the missing data__:

1.    Impute the missing values using an appropriate model that incorporates random variation.
2.    Repeat the imputation process 3-5 times.
3.    Perform the desired analysis on each imputed dataset using standard methods for complete data.
4.    Average the parameter estimates across the imputed datasets to obtain a single point estimate.
5. Calculate standard errors by averaging the squared standard errors of the estimates from the imputed datasets. 


Within CRAN, there are a number of packages associated with Multiple Imputation.


### Assumptions for multiple imputation: types of missing data

In 1976, Rubin classified types of missing data into three categories: MCAR, MAR, and MNAR.

-   __MCAR = Missing Completely at Random__: data points are missing at random, meaning that the pattern of missing values is uncorrelated with the structure of the data. For example: a random sample taken from the population (everyone had the same chance of being included in the sample)

-  __MAR = Missing at Random__: the likelihood of missing data is determined by the observed data, not the missing data itself. For instance, if a survey respondent opts not to disclose their income due to privacy concerns &#8594; the missing value for income can be inferred by examining responses to other personal information questions.

-   __MNAR = Missing Not at Random__: the missing data isn't random; it is associated with unobservable traits. For instance, in surveys, social desirability bias can lead respondents with certain characteristics, which we cannot systematically observe, to avoid answering questions related to sensitive topics such as racial issues.

While MCAR is desirable, in general, it is unrealistic for the data. All multiple imputation techniques start with the MAR assumption that missing values can be replaced by predictions derived from the observable portion of the dataset. This is a fundamental assumption; otherwise, we wouldn’t be able to predict plausible values of missing data points from the observed data.


## Example of data imputation

```{r hide=T}
library(ggplot2)
library(readr)
library(dplyr)
library(cowplot)
#install.packages("explore")
library(explore)
#install.packages("titanic")
library(titanic)
library(patchwork)
#install.packages("missForest")
```

Read the data set _titanic_train.csv_
```{r}
titanic <- as_tibble(titanic_train)
titanic |> describe_tbl()
titanic |> describe()
table(is.na(titanic))
```
Age is the only continuous variable containing missing data. The other two, cabin and embarch, are character variables. Let's see the distribution of Age

```{r}
ggplot(titanic, aes(Age)) +
  geom_histogram(binwidth = 1,   color = "skyblue3", fill = "skyblue") +
  ggtitle("Distribution of the Age variable") +
  theme_classic() +
  theme(plot.title = element_text(size = 18))

```

### Simple value imputation
There are straightforward ways to impute missing values. For example:

-   Constant imputation: Zero or another specified value
-   Mean: Average age after all NA's are removed.
-   Median: Median age after all NA's are removed


```{r}

value_imputation <- titanic |>
  mutate(
    original = Age,
    imputed_zero = if_else(is.na(Age), 0, Age),
    imputed_mean = if_else(is.na(Age), mean(Age, na.rm = TRUE), Age),
    imputed_median = if_else(is.na(Age), median(Age, na.rm = TRUE), Age)
  ) 

head(value_imputation, 10)
```


Once the data has been imputed, let's compare the distributions of the four variables

```{r}
# Define variables, titles, and colors
variables <- c("original", "imputed_zero", "imputed_mean", "imputed_median")
titles <- c("Original Age Distribution", "Zero Imputation", "Mean Imputation", "Median Imputation")
colors <- c("skyblue3", "#15ad4f", "#6a6ad9", "#e65100")

# Initialize an empty plot list
plots <- list()

# Loop through variables to create plots
for (i in 1:length(variables)) {
  # Using .data[[ ]] to refer to dataframe columns in aes()
  plots[[i]] <- ggplot(value_imputation, aes_string(variables[i])) +
    geom_histogram(binwidth = 1, fill = colors[i], color = "#808080") + 
    labs(title = titles[i]) +
    theme_classic()
}

# Combine plots into a grid
install.packages("comwplot")
library(cowplot)
plot_grid(plotlist = plots, nrow = 2)
```

Imputing missing values with a single constant, like the mean or median, can skew the data's distribution. Although these statistics provide an overview, using them to fill in missing values can create an inaccurate distribution, particularly with many missing values. Using a single value, like zero, for imputation is especially problematic. For instance, it's highly unlikely for about 200 passengers in a dataset to all be aged zero, highlighting the unsuitability of zero imputation.


### Multiple imputation with MICE

[MICE](https://search.r-project.org/CRAN/refmans/mice/html/mice.html), which stands for Multivariate Imputation by Chained Equations, is a widely used package among R users for handling missing data. It operates under the assumption that missing values occur at random (MAR), implying that the likelihood of a value being missing is determined solely by observable data, allowing for predictions based on those observed values. It's important to note, as previously mentioned, that the assumption of missing completely at random (MCAR) is often unrealistic in practical scenarios.

The basic idea behind the algorithm is to treat each variable that has missing values as a dependent variable in regression and treat the others as independent (predictors). In the reference section you can find documentation and papers using MICE for MI. 

By default, the mice package uses the following:

-   PMM (Predictive Mean Matching) &rarr; numeric variables
-   logreg(Logistic Regression) &rarr; binary variables (with 2 levels)
-   polyreg(Bayesian polytomous regression) &rarr; factor variables (>= 2 levels)
-   Proportional Odds Model &rarr; ordered variables (>= 2 levels)

But many other options are available. Check [here](https://www.rdocumentation.org/packages/mice/versions/3.14.0/topics/mice). 

After completing this process, several datasets are created, differing only in the imputed values for the missing data. It is generally recommended to analyze these datasets separately and then integrate their findings. 

<center>
![](mice_method.png){width=500px}
</center>

Now, let's delve into a practical application, focusing initially on continuous variables. 

```{r}
library(mice)
titanic_numeric <- titanic |>
  select(Survived, Pclass, SibSp, Parch, Age)
```

Mice package has a function known as `md.pattern()´ to get a better understanding of the pattern of missing data. It returns a tabular form of missing value present in each variable in a data set.
```{r}
md.pattern(titanic_numeric) 
```

Mice returns an S3 object of class MIDS (Multiple Imputation Data Sets). The main functions are:

-   `mice()`:	Impute the missing data *m* times
-   `with()`: Analyze completed data sets
-   `pool()`: Combine parameter estimates
-   `complete()`:	Export imputed data
-   `ampute()`: Generate missing data

Moving on to the imputation process, we will employ the following MICE imputation methods:

-   pmm: predictive mean matching (default)
-   cart: classification and regression trees
-   laso.norm: lasso linear regression


```{r results='hold'}
library(mice)
mice_imputed <- data.frame(
  original = titanic$Age,
  imputed_pmm = complete(mice(titanic_numeric, m=5, method = "pmm", seed=123))$Age,
  imputed_cart = complete(mice(titanic_numeric, m=5, method = "cart", seed=123))$Age,
  imputed_lasso = complete(mice(titanic_numeric, m=5, method = "lasso.norm", seed=123))$Age
)
```

A couple of notes on the parameters:

-   `m=...` refers to the number of imputed datasets. Five is the default value.
-   `meth='...'` refers to the imputation method. Remember that other imputation methods can be used, type methods(mice) for a list of the available imputation methods
-   `complete`


```{r}
head(mice_imputed, 10)
```

Let`s plot the results: 
```{r}
# Define variables, titles, and colors for the updated set of distributions
variables <- c("original", "imputed_pmm", "imputed_cart", "imputed_lasso")
titles <- c("Distribution of the Age variable", "PMM-imputed distribution", "Cart-imputed distribution", "Lasso-imputed distribution")
colors_fill <- c("skyblue", "#15ad4f", "#6a6ad9", "#e65100")
colors_border <- c("skyblue3", "#808080", "#808080", "#808080")

# Initialize an empty plot list for the new plots
plots <- list()

# Loop through the updated variables to create plots
for (i in 1:length(variables)) {
  plots[[i]] <- ggplot(mice_imputed, aes(x = .data[[variables[i]]])) +
    geom_histogram(binwidth = 1, fill = colors_fill[i], color = colors_border[i], position = "identity") +
    ggtitle(titles[i]) +
    theme_classic()
}

# Combine the new set of plots into a grid
plot_grid(plotlist = plots, nrow = 2, ncol = 2)

```
Remember that you can try any algorithm from [this list](https://www.rdocumentation.org/packages/mice/versions/3.14.0/topics/mice). 


### Multiple imputation with Miss Random Forest
The [Miss Forest](https://cran.r-project.org/web/packages/missForest/missForest.pdf) imputation technique is based on the Random Forest algorithm. This means it operates without making explicit assumptions about the underlying distribution of the data. Instead, Miss Forest estimates missing values by closely approximating the inherent patterns within the dataset.

In practical terms, Miss Forest builds a random forest model for each variable and then uses the model to predict missing values. This approach is versatile, accommodating both numerical and categorical data, and is particularly useful for complex datasets where traditional imputation methods may fall short.

For those interested in deeper insights, further reading and studies on the Miss Forest technique can be found in the referenced articles below.

To demonstrate the application of Miss Forest in R, the process involves applying the technique across a numerical dataset, with a focus on imputing missing values specifically within the 'age' variable.

```{r}
#install.packages("missForest")
library(missForest)
missForest_imputed <- data.frame(
  original = titanic_numeric$Age,
  imputed_missForest = missForest(as.data.frame(titanic_numeric), ntree = 15)$ximp$Age)
```

Let's check the resulting data.frame:

```{r}
head(missForest_imputed, 10)
```

Finally, let’s visualize the distributions:
```{r}
# Define variables, titles, and colors for the plots
variables <- c("original", "imputed_missForest")
titles <- c("Distribution of the Age variable", "Miss Forest-imputed distribution")
colors_fill <- c("skyblue", "#FFD700") # Fill colors for the histograms
colors_border <- c("skyblue3", "#808080") # Border colors for the histograms

# Initialize an empty list to store the plots
plots <- list()

# Loop through the variables to create each plot
for (i in 1:length(variables)) {
  plots[[i]] <- ggplot(missForest_imputed, aes(x = .data[[variables[i]]])) +
    geom_histogram(binwidth = 1, fill = colors_fill[i], color = colors_border[i], position = "identity") +
    ggtitle(titles[i]) +
    theme_classic()
}

# Combine the plots into a grid, specifying the layout
plot_grid(plotlist = plots, nrow = 1, ncol = 2)
```

The observed distribution significantly deviates from the original, with a notable concentration of values around age 35. This indicates that the Miss Forest imputation technique may not be the most suitable option for this particular scenario.

### Multiple imputation with Amelia

Amelia II imputes missing data in a single cross-section (such as a survey), from a time series (like variables collected for each year in a country), or from a time-series-cross-sectional data set (such as collected by years for each of several countries). Amelia II implements a bootstrapping-based algorithm. More info [here](https://gking.harvard.edu/amelia)

How it works? 

1. it takes m bootstrap samples and applies EMB algorithm to each sample. 
2. the first set of estimates are used to impute first set of missing values using regression, then second set of estimates are used for second set and so on.

Amelia II might be particularly interesting for multiple imputation in time series. [Check here](https://cran.r-project.org/web/packages/Amelia/vignettes/using-amelia.html) for an example of Amelia using data from Milner and Kubota (2005) which studies the effect of democracy on trade policy.


## Runing regressions with MICE

Let's assume the goal of our analysis involves applying a generalized linear model (GLM) to the dataset in order to calculate the likelihood of survival from the shipwreck. We'll use the "cart" method, which we have identified as the most effective approach.

The literature presents an intense debate regarding whether the dependent variable should be imputed. While it is accepted that the outcome should be included in the imputation model when imputing missing covariate values, [it is not clear whether the outcome itself should be imputed]((https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-016-0281-5). According to the literature, there are advantages and disadvantages to both approaches. In our example, we will use the variable 'Survived' to impute missing data in 'Age,' but we won't impute the missing data in the outcome variable.


Prepare data for MI
```{r}
init = mice(titanic_numeric)
meth = init$method
```

Specify the method for imputing the missing values. The missing values of variables not included in this vector will not be imputed:

```{r}
meth[c("Age")]="cart"
#Only Age had the NAs. 

```

Now we're going to include the imputation formula. M=5 means that we're going to make 5 imputations for each value (actually, 5 it's the default value, so it wouldn't be necessary to include it). Additionally, set a seed to always obtain the same results.

```{r}
imputed_cart <- mice(titanic_numeric, method=meth, m=5, seed=123)
summary(imputed_cart)
```

To check the imputed data, simply execute the code line below. This will display the imputed data for each observation, positioned in the first column on the left, across each of the five imputed datasets we have.

```{r}
imputed_cart$imp$Age
```

We can get back the completed dataset using the `complete()` function. The missing values have been replaced with the imputed values in the first of the five datasets. If you wish to use another one, or all, just change the second parameter in the function.
function.

```{r}
completed_imputed_1 <- complete(imputed_cart, 1)# Replace missing data with imputed data in the first dataset
completed_imputed_2 = complete(imputed_cart, 2)
completed_imputed <- complete(imputed_cart, "all") # List of 5 datasets
completed_imputed[[2]]
completed_imputed[[1]]
```

The  next step is to fit a generalized linear model (GLM) to the data to estimate the survival probability. You might wonder which imputed dataset to select. The `mice` package simplifies this process by allowing us to fit a model to each imputed dataset and then aggregate the results using `pool()`.

```{r}
# Original regression with NAs
model0 <- with(titanic_numeric, glm(Survived ~ Pclass + SibSp + Parch + Age))
summary(model0)

# Regression with 5 imputed datasets
model1 <- with(imputed_cart, glm(Survived ~ Pclass + SibSp + Parch + Age))
model1[[3]]
summary(pool(model1))
```

The variable model1 contains the results of the fitting performed over the imputed datasets, while the `pool()` function pools them all together. As observed, all variables in the model are statistically significant. 

## References

About missing data and inference:

- [Rubin, Donald B. 1976. “Inference and missing data.” Biometrika 63, no. 3: 581-592](Rubin, Donald B. 1976. “Inference and Missing Data.” Biometrika 63 (3): 581–92. http://www.jstor.org/stable/2335739)

About the _mice_ method approach:

-   https://www.rdocumentation.org/packages/mice/versions/3.14.0/topics/mice

-   https://www.jstatsoft.org/article/view/v045i03

About the _missForest_ method 

-   https://academic.oup.com/bioinformatics/article/28/1/112/219101?login=false

Missing values on time series:

-   James Honaker and Gary King, "What to do About Missing Values in Time Series Cross-Section Data" American Journal of Political Science Vol. 54, No. 2 (April, 2010): Pp. 561-581. 

-   Matthew Blackwell, James Honaker, and Gary King.  A Unified Approach to Measurement Error and Missing Data: Overview and Details And Extensions both in Sociological Methods and Research, forthcoming.

On whether or not the DV is to be imputed

-   Kontopantelis, E., White, I. R., Sperrin, M., & Buchan, I. (2017). Outcome-sensitive multiple imputation: A simulation study. BMC Medical Research Methodology, 17(1). https://doi.org/10.1186/s12874-016-0281-5

